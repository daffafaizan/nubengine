
    
      The study will advance through two distinct phases.

        -  Phase 1 has two main stages: The first stage will identify unique tumor phenotypes based
           on the iBiopsy phenotyping platform which extracts image-based signatures corresponding
           to each individual phenotype and will assess the analytic/technical performance of the
           iBiopsy platform. Gaps in characterization of the analytic readout under varying
           conditions of image acquisition and the repeat variability under identical analytic
           conditions will be filled by the proposed design. Once a set of suitable tumor
           phenotypes have been identified they will advance to the characterization phase. This
           will be done by the evaluation of an initial representative specific dataset (e.g.
           hundreds of patients) for training (to discover) and validation (to test robustness).
           The second stage will complete a preliminary biological/clinical validation of the above
           phenotypes for diagnosis and disease subtyping. This includes the investigation of a
           large dataset (e.g. thousands of patients) CDR for training and validation, using
           histopathology data as the reference standard and the optimization of the imaging
           signatures using AI based learning methodologies.

        -  Phase 2 also has two stages. The first stage of Phase 2 is to rigorously validate the
           candidate phenotypes emerging from Phase 1 for the diagnosis of subjects with HCC. The
           second stage of Phase 2 is to validate these select candidate phenotypes for prediction
           of outcome. These rigorous validations include using large CDR of patients with HCC
           (late stage biological/clinical validation).

      Traditional medical image retrieval systems such as Picture Archival Systems (PACS) use
      structured data (metadata) or unstructured text annotations (physician reports) to retrieve
      the images. However, the content of the images cannot be completely described by words, and
      the understanding of images is different from person to person, therefore text-based image
      retrieval system cannot meet the requirements for massive images retrieval. In response to
      these limitations, CBIR systems using visual features extracted from the images in lieu of
      keywords have been developed. An important and useful outcome of these CBIR is the
      possibility to bridge the semantic gap, allowing users to search an image repository for
      high-level image features allowing the matching of image-based phenotype signatures extracted
      directly from the query medical image with phenotype signatures indexed in a registry.

      The Median Technologies CBIR system uses patented algorithms and processes to decode the
      images by automatically extracting hundreds of imaging features as well as highly compact
      signatures from tens of thousands of 3D image patches computed across the entire image
      without the need for any prior segmentation. In addition to detailed phenotypic profiles
      which can be correlated with histopathology and genomic and plasmatic profiles, the system
      generates a unique signature for each tile providing a fingerprint of the "image-based
      phenotype" of the corresponding tissue. Using massively parallel computing methods, imaging
      biomarkers and phenotype signatures are extracted from a target image are then organized into
      clusters of similar signatures and indexed for real-time search and retrieval into
      schema-less (NoSQL) databases.
    
  