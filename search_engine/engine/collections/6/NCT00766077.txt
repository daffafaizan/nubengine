
    
      Stress fractures are among the most prevalent sports injuries, particularly in sports
      involving running, jumping, and repetitive cyclic loading. Stress fractures have been
      diagnosed in as many as 20% of athletes. The highest prevalence of stress fractures among
      athletes is reported in members of track and field teams with rates from 10-31% (22). Stress
      fractures are also a common occurrence in military basic training. U.S. military reports from
      the recruit populations indicate an incidence rate of 0.2 to 4% in men, and 1 to 7% in women
      (1).

      Due to the prevalence of stress fractures in the military and athletic population, as well as
      the costly nature of the injury in terms of recovery time, it is important to understand the
      causative factors and the means by which these factors relate and interact (25, 29) . The
      most commonly studied and measured risk factors for stress fractures are surrogates of bone
      strength-particularly bone mineral density. Although several previous studies have explored
      the relationship of areal bone mineral density (aBMD, g/cm2) to stress fractures, the
      findings remain controversial (6, 7, 9, 12, 17, 28). A majority of these studies have used
      dual energy x-ray absorptiometry (DXA) and aBMD as the assessment of bone strength. DXA is
      limited in its 2-dimensional assessment of a 3-dimensional bone and is also unable to
      distinguish between different types of bone(13, 30). Given the limitations of DXA imaging,
      measuring bone properties using peripheral Quantitative Computed Tomography (pQCT) may shed
      light on inconsistencies found in the current literature. Peripheral QCT is a 3-dimensional
      imaging technique that allows for measurement of both trabecular and cortical volumetric bone
      density, bone geometry (total area, cortical area), and estimates of bone mechanical strength
      (i.e. cross-sectional moment of inertia and section modulus) which better represent a bones
      mechanical competence (26, 31).

      With any fracture, a bone will fail only if the load on the bone is higher than the strength
      of that bone. In the case of stress fractures, it has been suggested that those at risk for
      stress fracture may alter biomechanics with fatigue such that strain on bone is increased
      with fatigue causing an increase in microdamage and ultimate fracture. Research measuring
      kinetic and kinematic variables has shown changes in GRFs (10, 11, 16, 19, 21), strain
      magnitude, strain rate, strain distributions (8, 14, 15, 24), and landing strategies after
      the onset of muscle fatigue in healthy individuals. It has also been shown that when muscles
      are fatigued, their ability to absorb impact forces during landing, their internal timing
      ability between functioning muscle groups, and ability to counter bending moments is
      decreased (2-5, 18, 20, 23). It has been hypothesized that runners who are ineffective at
      altering movement kinematics experience greater increases in loading rates and impact
      magnitudes, making them more susceptible to injury than runners who are able to make
      appropriate alterations (16). However, the majority of these studies have been conducted
      during resting conditions and in athletes with no history of injury. No previous studies to
      our knowledge have adequately characterized the change in biomechanics during a fatiguing run
      in athletes with and without a history of stress fracture.
    
  