
    
      Introduction Sensorineural hearing loss (SNHL) is a disability affecting people worldwide,
      and the prevalence is expected to increase due to prolonged life expectancy. SNHL has a
      significant negative impact on the quality of life, especially in prelingually deafened
      children. Except for certain diseases such as sudden deafness or endolymphatic hydrops, which
      may be treated or alleviated by medication or surgery, most patients with SNHL have to wear
      hearing aids or undergo cochlear implantation to regain hearing. However, for many
      individuals these measures do not satisfactorily resolve communication problems, because
      hearing is only the first step in a series of events leading to communication. Between
      hearing and communication lie the important skills of listening and comprehension, and to
      achieve successful communication it has been suggested that patients receiving amplification
      should be offered some type of audiological rehabilitation. It has been reported that older
      subjects do not spontaneously acclimatize to wearing a hearing aid, or that the effects are
      either small or nonexistent, which emphasizes the importance of rehabilitation after wearing
      a hearing aid. Unfortunately, not everyone with SNHL in Taiwan receives this kind of
      rehabilitation. The reasons for this may be: (a) methods of rehabilitation are not familiar
      to all clinicians or speech pathologists; (b) there is a shortage of clinicians or speech
      pathologists to provide such time-consuming rehabilitation; (c) hearing impaired patients may
      be unable to afford or are unwilling to dedicate time to rehabilitation; and (d) it is
      difficult to measure the improvements provided by rehabilitation.

      Recently, rehabilitative training procedures have been garnering interest due to
      technological advances enabling a hearing aid user to perform the procedures while at home
      using a personal computer. Burk et al trained young normal-hearing and older hearing-impaired
      listeners with digitally recorded training materials using a computer. The results showed
      that older hearing-impaired listeners were able to significantly improve their
      word-recognition abilities through training with one talker, and to some degree achieve the
      same level as young normal-hearing listeners. In addition, the improved performance was
      maintained across talkers and across time.

      The computer-aided speechreading training (CAST) system was developed to simulate a
      face-to-face training intervention and was designed to be one component of a comprehensive
      aural rehabilitation program for preretirement adults with acquired mild-to-moderate hearing
      loss. The aim of the training was to enhance speechreading skills to complement auditory
      speech perception. Throughout the training, the learner views a monitor that shows either a
      computer-generated screen or a videotaped recording of the teacher. CAST was designed to be
      used by a clinician to extend rather than to replace existing rehabilitative techniques.

      Computer-based training has also been applied to the rehabilitation of cochlear implant
      users. Before the development of computer-based training, some studies assessed the effects
      of limited training on the speech-recognition skills of poorer-performing cochlear implant
      users. Busby et al conducted ten 1-hour speech perception and production training sessions,
      and the results demonstrated minimal changes in perceptual abilities in three cochlear
      implant users. Dawson and Clark conducted one 50-minute training session per week for 10
      weeks, and four of five subjects showed some measure of improvement. The limited success of
      these attempts to improve the speech-recognition abilities of cochlear implant users was
      thought to be due to an inadequate amount of training. More intensive training of cochlear
      implant users was predicted to be effective, because in normal hearing populations training
      has been shown to successfully improve speech segment discrimination and identification, and
      recognition on spectrally shifted speech. Fu et al reported encouraging results in the
      rehabilitation of cochlear implant users using a computer-assisted speech training system
      which they also called CAST, although this was different to the CAST system of Pichora-Fuller
      and Benguerel. The CAST system of Fu et al, developed at the House Ear Institute, contains a
      large database of training materials and can be installed on personal computers, and so with
      minimal facilities and skills, cochlear implant users can conduct the training at home, and
      clinicians or speech pathologists can monitor the subject's test score and training progress.
      The results demonstrated that after moderate amounts of training (1 hour per day, 5 days per
      week), all 10 postlingually deafened adult cochlear implant users in the study had
      significant improvements in vowel and consonant-recognition scores. Wu et al applied the CAST
      system to 10 Mandarin-speaking children (three hearing aid users and seven cochlear implant
      users). After training for half an hour a day, 5 days a week, for a period of 10 weeks, the
      subjects showed significant improvements in vowel, consonant and Chinese tone performance.
      This improved performance was largely retained for 2 months after the training had been
      completed. Stacey and Summerfield also used computer-based auditory training to improve the
      perception of noise. The results confirmed that the training helped to overcome the effects
      of spectral distortions in speech, and the training materials were most effective when
      several talkers were included.

      Based on these previous studies, cochlear implant users can improve their speech recognition
      ability after training with a CAST system. If this system is also effective for hearing aid
      users, and especially prelingually deafened patients, the CAST system will have a
      substantially positive impact, as there are many more hearing aid users than cochlear implant
      users.

      The purpose of this study was to train prelingually deafened adolescents and young adults
      with CAST and measure the benefits objectively and subjectively. The objective benefits were
      measured using published speech recognition tests [13], and the subjective benefits were
      measured using client-oriented scale of improvement (COSI).

      Materials and Methods Subjects Fifteen hearing aid users with prelingual severe to profound
      hearing loss participated in this study. Another six hearing aid users with a similar age and
      hearing average were included as the control group. The inclusion criteria for the study
      subjects and controls were: (1) age above 15 years; (2) wearing a hearing aid for at least
      for 2 years after hearing loss was diagnosed; (3) basic ability to operate a computer; (4)
      Mandarin Chinese speaker; and (5) motivation to undertake the training program. The exclusion
      criteria were: (1) aided hearing average worse than 70 dBHL; (2) unable to operate a
      computer. Before training with CAST, all participants received unaided and aided sound field
      audiometry. Table 1 shows the basic information of the 21 participants.

      Client-oriented scale of improvement (COSI) We use a COSI questionnaire to evaluate
      subjective benefits. Before training with the CAST system, both the training and control
      groups were asked to identify up five specific situations in which they would like to cope
      better. At the end of the training, for each situation they were asked (A) how much better
      (or worse) they could now hear, and (B) how well they were now able to cope. For scaling
      purposes, the responses were assigned scores from 1 to 5, with 5 corresponding to "much
      better" and "almost always", 4 corresponding to "better" and "most of the time", 3
      corresponding to "slightly better" and "half the time", 2 corresponding to "no difference"
      and "occasionally", and 1 corresponding to "worse" and "hardly ever", for questions A and B,
      respectively. Question A was defined as an "improvement", and question B was defined as
      "final ability". The total scores of the five situations were compared between the training
      and control groups.

      Test materials and procedures The speech recognition test materials including monosyllabic
      words, disyllabic spondee words, vowels, consonants and Chinese tone recognition tests were
      recorded onto a CD-ROM at Melody Medical Instruments Corp. by a male and female speaker. The
      test materials were displayed on a laptop computer connected to a GSI 61TM clinical
      audiometer (Grason-Stadler, USA) at an output level of 70 dBHL. The testing procedure was
      performed in a double-walled, sound-treated room.

      Monosyllabic Chinese word recognition test materials included four blocks of 25 Chinese
      words. For each speech recognition test, 50 words were selected resulting in a set of 50
      tokens. After a monosyllabic Chinese word was displayed, the participants were asked to write
      down the word. Four different sets of open-set tests were generated for each speech
      recognition test. Disyllabic Chinese spondee-word recognition test materials included two
      blocks of Chinese spondee-words, each block containing 36 Chinese spondee-words. For each
      speech recognition test, one block was selected resulting in a set of 36 tokens. After a
      Chinese spondee-word was displayed, the participants were asked to write down the word. Four
      different sets of open-set test were generated via changing the order of the materials for
      each speech recognition test.

      Vowel recognition test materials included 16 Chinese words. Vowel recognition was measured
      using a 4-alternative, forced-choice procedure in which Chinese characters were shown on the
      choice list. For each speech recognition test, the order of the words was changed. Thus, four
      different sets of closed-set tests were generated. Consonant recognition test materials
      included 21 Chinese words. Consonant recognition was measured using a 4-alternative,
      forced-choice procedure in which a Chinese character was shown on the choice list. For each
      speech recognition test, the order of the words was changed, and thus four different sets of
      closed-set tests were generated. Chinese tone recognition test materials included 50 Mandarin
      Chinese words. The participants were asked to write down the Chinese tone (tone: 1: flat; 2:
      rising; 3: falling-rising; 4: falling) after the Chinese word was displayed. For each speech
      recognition test, the order of the words was changed, and thus four different sets of
      open-set tests were generated.

      Before training, both groups underwent a series of speech recognition tests as baseline data.
      The training group then started training whereas the control group did not receive any
      training. Every 4 weeks, the participants returned to the lab for another series of speech
      recognition tests using different test materials. Every participant had received a total of
      four speech recognition tests by the end of the study.

      Training tools and procedures CAST software developed at the House Ear Institute and
      distributed by Melody Medical Instrument Corp. was used as the training tool. The training
      group was instructed to train at home following the program for at least 1 hour per day, 3
      days a week, for 12 successive weeks. The control group did not receive any training and
      returned to the lab every 4 weeks for speech recognition tests. For each participant in the
      training group, a baseline speech recognition test was performed after the software had been
      installed into his or her personal computer. The results were analyzed by the software which
      then automatically generated a targeted training program. The software contained a large
      amount of information including pure tone, vowel recognition, consonant recognition, tone
      recognition, speaker recognition, environmental sounds, occasional words and occasional
      sentences. The subjects were asked to focus on pure tone, vowel recognition, consonant
      recognition and tone recognition training. The subjects started the training at a level
      generated by the computer software. There were usually five levels of difficulty in each
      training category, and each level consisted of several training sessions. For pure tone
      recognition training, the subjects were asked to choose the sound different to the others.
      Visual feedback was provided as to whether the response was correct or incorrect. After a
      training session had been completed, the score was calculated. If the score exceeded 80, the
      training proceeded to a higher level. If the score did not exceed 80, the training session
      was repeated until the score exceeded 80. At a higher level of training sessions, the
      differences between speech features in the response choices were reduced. For vowel
      recognition training, the subjects were asked to choose the vowel different to the others.
      After the subjects had progressed beyond the 3-alternative forced-choice discrimination task,
      they were trained to identify final vowels. Similar training procedures were used for
      consonant and tone recognition training.

      Each subject in the training group was asked to register on the Melody Medical Instrument
      Corp. website, and his or her username and password were provided to us. Therefore, we were
      able to monitor the total time spent training, and the training time and score for each
      exercise. If the subjects did not reach the required amount of time and training sessions, we
      contacted their family and encouraged them to do more training.

      Statistical methods All statistical analyses were performed with SAS software (Version 9.1.3,
      SAS Institute Inc., Cary, NC, U.S.A.) and R software (Version 2.7). Two-sided p values of
      0.05 or less were considered to be statistically significant. Continuous data were expressed
      as mean ± standard deviation (SD) unless otherwise specified. Percentages were calculated for
      categorical variables. Two-sample t tests or Wilcoxon rank-sum tests were used to compare the
      means or medians of continuous data between two groups, whereas the chi-squared test or
      Fisher's exact test was used to analyze categorical proportions between two groups.

      In addition to univariate analyses, the data of the five speech recognition tests were
      analyzed by fitting multiple marginal linear regression models using generalized estimating
      equations. If the first-order autocorrelation (i.e., AR(1)) structure fit the repeated
      measures data well, the model-based standard error estimates were used in the generalized
      estimating equations analysis; otherwise, the empirical standard error estimates were
      reported. In addition, the data of COSI were analyzed by fitting multiple linear regression
      models.

      Basic model-fitting techniques for variable selection, goodness-of-fit assessment, and
      regression diagnostics were used in our regression analyses to ensure the quality of the
      results. In stepwise variable selection, all of the univariate significant and
      non-significant covariates were considered, and both the significance levels for entry and
      for stay were set to 0.15 or larger. The goodness-of-fit measure, the coefficient of
      determination (R2), was computed for all of the linear regression models, which is the square
      of the correlation between the observed response variable and the predicted value. It had a
      value between 0 and 1, with a larger value indicating a better fit of the multiple linear
      regression model to the observed continuous data. In addition, the variance inflation factor
      was examined to detect potential multicollinearity problems (defined as a value ≥ 10).
    
  