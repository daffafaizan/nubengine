
    
      Healthcare processes are measured, evaluated, and characterized through the use of healthcare
      quality measures. Healthcare quality measures are tools that quantify the consistency of care
      delivery within a population eligible for the process. Containing a numerator (those with
      successful delivery of a care process) and a denominator (eligible patients for that care
      process), quality measures produce a frequency or adherence rate to which a care process was
      performed. Adherence rates can then be compared to evaluate quality of care across
      clinicians, organizations, or collaborations to compare data, establish benchmarks, and spur
      quality improvement projects.

      In palliative care, for example, it is usually considered best practice to prescribe opioids
      for moderate/severe pain. Imagine that a palliative care program's calculated adherence rate
      reveals that their clinicians prescribe opioids for moderate-to-severe pain only 50% of the
      time. Armed with this information, the program can now develop a directed quality improvement
      project with the intention of improving this performance towards a more ideal goal (e.g.
      75%). Further, it can provide feedback to clinicians in real-time regarding how they are
      performing against the quality measures of interest. In this example, clinicians may receive
      an electronic alert reminding them to prescribe an opioid when directed by an accepted best
      practice. This real-time approach, combined with a system that promotes culture of data
      collection, sharing, benchmarking, and reporting, are effective methods to improve healthcare
      quality. Lastly, and the focus of this proposal, is to build and test such an infrastructure
      that performs such real-time quality monitoring of healthcare measures in the Palliative Care
      Research Cooperative group (PCRC).

      The investigators have previously identified the three major components needed for an
      effective and usable quality-monitoring infrastructure. Together, these three components
      answer the "what", "how", and "for why" questions that must be addressed within a quality
      assessment and improvement system.

      First, is the ability to perform collaborative and integrated data collection across several
      sites. Successful multi-site data collection requires a centrally governed set of data
      collection processes, which are guided by a data dictionary. A data dictionary is a set of
      agreed-upon data elements, answer choices, rules, and branching logic. The data dictionary
      informs the development of a data collection platform for use by clinicians. Together, the
      data dictionary and software for use by clinicians guide "what" data is collected, and ensure
      that the intended collaborative analyses can be performed with the data set created.

      Second, is the process for data collection - the "how" characteristic within the system. Data
      is collected, transmitted and recorded through the use of a data collection platform,
      transmission processes, and registry, respectively. The data collection platform is the
      interface in which real-time data is captured and recorded. This can involve paper-based or
      electronic forms using patient, caregiver, or clinician reporters. Data is then transmitted
      to the registry, either through electronic or manual means. Lastly, data is collected and
      securely stored in a prospective registry, so quality reports can be generated and research
      analyses completed. These steps are recommended standards for development of health
      information technology by the Agency for Healthcare Research and Quality (AHRQ).

      Third, is the component of the infrastructure that answers the question, "for why?" Several
      reports have highlighted the need to translate raw data from quality monitoring efforts into
      continuous feedback on quality to clinicians and other end-users to motivate the delivery of
      best practices. This allows for changes in clinician performance during usual clinical care
      delivery, thus meeting the Institute of Medicine's aim for a rapid learning healthcare
      system. Generally, feedback is provided through system-generated reports that target specific
      end-users (e.g. clinicians, administrators) delivered during pre-specified time periods (e.g.
      weekly, quarterly).

      At Duke University, investigators recently built the information technology infrastructure
      needed for prospective quality measure adherence and outcomes monitoring in palliative care.
      This system was developed and deployed in the Carolinas Consortium for Palliative Care, a
      four-site collaboration between Duke University and three community palliative care
      organizations. Recently, this Consortium has expanded to include organizations outside the
      Carolinas; eleven sites now comprise the Global Palliative Care Quality Alliance (GPCQA). The
      rapid expansion of qdact users and subsequent data collected have supported several
      research-level analysis published in the literature.

      In using qdact.pc, clinicians record data on processes of care and patient-reported outcomes
      on personal iPadsÂ® during face-to-face clinical encounters with patients. During patient
      interviews, clinicians record patient-reported areas of distress, clinical management
      decisions, and patient-reported outcomes using validated instruments. These instruments
      include those common to the field, including the Edmonton Symptom Assessment Scale (ESAS),
      Palliative Performance Scale, and FACT-G. Longitudinal changes in these scales are captured
      through repeat use of qdact.pc during subsequent encounters. Further, qdact.pc calculates
      length of stay from admission and discharge dates, changes in symptom severity by calculating
      the difference between two dates, and readmission rates by analyzing whether patients in the
      registry had previously been admitted. Then, care processes and outcomes can be linked using
      these data.
    
  