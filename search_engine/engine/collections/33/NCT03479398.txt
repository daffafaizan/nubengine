
    
      Cognitive Behavioral Therapy (CBT) has been demonstrated to be effective for numerous
      presenting problems, including depression, anxiety, and post-traumatic stress disorder
      (PTSD). Several large mental health systems have invested heavily in programs to train their
      clinicians in CBTs, but relatively little attention has been devoted to the monitoring or
      promotion of CBT quality after training is complete. Identifying strategies to do so can
      facilitate research and training, and is critical to ensuring consumer access to high
      quality, evidence-based treatments. The lack of a scalable, effective, and efficient method
      of monitoring quality is a key barrier to efforts to promote high-quality implementation.
      Self-report fidelity assessments increase clinician and consumer burden and may not
      accurately reflect clinician skill or the intensity with which CBT interventions are
      delivered. Observation and expert ratings are time and resource intensive and unlikely to be
      feasible or affordable in large systems. To maximize the likelihood of broad implementation
      once effective strategies to monitor quality are established, it is essential that these
      strategies are feasible and acceptable in routine care contexts, leveraging information
      collected during routine care. To date, few monitoring strategies that do not involve
      observation, client/caregiver reports, or clinician self-reports have been tested. To address
      this critical implementation challenge, we propose to refine and evaluate a method of
      monitoring quality that is based on an evaluation of CBT worksheets that are completed in
      session. Because the worksheets were developed to implement core cognitive and behavioral
      elements and are embedded in CBTs across diagnostic categories, they may be used to elucidate
      the clinician's ability to guide the client through CBT interventions in session. Preliminary
      research with this measure demonstrated high correlations between the measure and observer
      ratings of clinician competence, associations with subsequent symptom change, and high
      agreement between raters with differing levels of familiarity with CBT. Completion of the
      ratings based on worksheets requires only a small fraction of time required for session
      observation and ratings. This project will compare this novel strategy to observer ratings
      and adherence checklists that are embedded in clinical notes. Furthermore, it will compare
      the accuracy of worksheet data collected by mobile app to paper-form worksheets, and assess
      the feasibility and acceptability of these strategies. Because the core elements of CBT and
      its worksheets are common across many CBTs, this research has broad implications for
      monitoring fidelity to CBTs in a variety of mental health and healthcare systems and
      settings. This research will be conducted by a team of investigators with expertise in CBT,
      training, implementation, psychotherapy process and outcome research, psychometrics,
      longitudinal data analysis, mobile technologies and healthcare economics, with input from
      community partners and end-users. The resulting products have the potential to significantly
      improve efforts to monitor and ensure ongoing high quality implementation of CBT in routine
      care settings.
    
  