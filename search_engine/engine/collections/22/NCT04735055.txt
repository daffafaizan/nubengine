
    
      In a retrospective way, 1550 patients who were followed up at the Gastroenterology Clinic of
      Bezmialem Foundation University between October 2010 and February 2020 period and who were
      diagnosed with AP according to Atlanta criteria were screened. After the removal of 360
      patients with missing data, 1189 patients were included in the study for evaluation. Then,
      the study will be evaluated in the other 87 patients' (those admitted between February-August
      2020 period) by unaware of the results to the artificial intelligence operator about outcomes
      such as complications, need for ICU, interventional procedures, etc. So, the total patient
      number is 1267. The data obtained will be obtained from routine file data between 2010 and
      2020.

        1. Patient demographic information; [age (yo), gender (male/female), cigarette/alcohol
           usage (as yes or no)], clinical information; [height (centimeters), weight (kilograms),
           BMI (as kg/m2), presence of diabetes mellitus and hypertension (yes or no)], etiology of
           AP such as gallstones, alcohol, etc., and laboratory tests those taken within the first
           24 hours of the admission; [CRP level (mg/dl, normally: 0-5), BUN level (mg/dl,
           normally; 9,8 - 20,1), creatinine level (mg/dl, normally; 0,57 - 1,11), number of
           leukocytes (normally 4.5 to 11.0 ×109/L) and hematocrit level (%, normally: 35,5-48%)],
           as well as Balthazar tomographic scoring [0: normal, 1: an increase in pancreatic size,
           2: inflammatory changes in pancreatic tissue and peripancreatic fatty tissue, 3:
           irregularly bordered, single fluid collection, 4: irregularly bordered 2 or more fluid
           collections, 5 to 10 different degrees of necrosis)], will be recorded in the excel
           file.

        2. Revised Atlanta scoring will also be recorded within a week period of hospital admission
           as mild, moderate, and severe scores. Infected pancreatic necrosis and sepsis that
           developed during the course of acute pancreatitis will be accepted as severe acute
           pancreatitis due to the inadequacy of some issues in Atlanta scoring. The severity of
           the disease will be evaluated according to the Atlanta scores. And the results of the
           artificial intelligence study will be matched according to the results of Atlanta
           scoring.

        3. Additionally, invasive procedure requirements such as endoscopic ultrasonography (EUS),
           endoscopic retrograde cholangiopancreatography (ERCP), length of hospital stay (as
           days), intensive care unit requirement (present or not), number of future AP attacks (in
           duration after a month of hospital admission), and survival (death, alive) will also be
           recorded.

      It is planned that with the help of machine learning methods, using the data given in the
      first paragraph, whether artificial intelligence (AI) can predict the severity of the
      disease. Atlanta scoring will be used as a guide in predicting how the severity of the
      disease will be. In addition, whether the situations in paragraph 3 will develop or not will
      be evaluated with artificial intelligence. During the machine learning study, patients will
      be grouped as; 70% of the patients (approximately 839) for model training; 15% (approx.179)
      validation, 15% (approx.179) reserved for testing suitable. Since cross-validation will also
      be applied to the model here, the data will also change within itself, and also the
      distribution will be optimized to increase the predictive power. Another 87-person patient
      group will also be used to validate the model hypothesis with data independent of the first
      data set, so it will be the second test data.

      Artificial Intelligence Methods of the Study

      Defining the Problem: The problem is defined as multiple output regression which involves the
      prediction of two or more numerical values using a data set consisting of multiple input
      properties. It is based on the estimation of values of the output variables defined by the
      input set, either in a time-dependent or time-independent fashion. This kind of problem can
      be solved and modeled by machine learning algorithms (linear regression, decision trees,
      etc.) based on the wrapper model, which naturally allows the use of multiple output
      regression.

      Regression describes a predictive modeling problem involving the estimation of a numerical
      value. In multiple-output regression, the outputs are connected to the input and to each
      other. This means that often the outputs are not independent of each other and a model may be
      required that predicts both outputs together or each output based on other outputs.
      Multi-step time series estimation can be thought of as a type of multiple output regression
      where a sequence of future values is predicted and each predicted value depends on previous
      values in the sequence.

      Solution Methodology: Although neural networks are widely known for modeling complex problems
      such as natural language processing, image recognition, they can be easily adapted to
      regression problems. Any class of statistical models can be called a neural network if it
      uses adaptive weights and can approximate nonlinear functions of its inputs.

      Therefore, neural network regression is appropriate for problems for which a more traditional
      regression model cannot provide a suitable solution. Neural network regression is a
      supervised learning method and therefore, it requires a dataset containing a column of
      labels. Since a regression model predicts a numeric value, the label column must be a numeric
      data type. The model and the labeled dataset are fed as input to the training model or
      hyperparameter tuning model. The trained model is then used to predict output values for new
      input samples. The deep neural network regression model is created using the Python-based
      KerasRegressor (TensorFlow-Keras API) library. The deep neural network regression model can
      predict many more parameters and parameter permutations than classical machine learning
      algorithms such as logistic regression. In order to obtain reliable estimates, the ratio of
      data points to parameters should be reasonable and there should be a sufficient number of
      samples.

      "GridSearchCV" is utilized for model hyperparameter fine-tuning (for hyperparameters such as
      dropout rate, regularization rate, momentum and learning rate, etc.). In the "GridSearchCV"
      method, a sequence of values are defined for each hyperparameter, and combinations of these
      values, i.e. a grid of hyperparameters are used to search for the most appropriate
      configuration of hyperparameters. Among a set of neural networks with varying topologies in
      terms of input, output and hidden layers and activation functions, the network model that
      yields the best performance is constructed. In every iteration, a value that represents that
      step is calculated before each correction to adapt the learning rate to a proper value that
      enables as fast convergence as possible while preventing the model from overshooting local
      minima. For training, the maximum number of iterations and batch size is determined. Feature
      normalization (binning, gaussian, min-max, rescaling, etc.) is applied. Samples are shuffled
      between iterations to have a different randomized order of samples at each iteration.

      A seed value, which is an optional value to define random seed is provided. Moreover,
      concerning the neural network architecture, it is possible to adjust visible layers, hidden
      layers, and dropout rates via unsupervised learning algorithms (stacked autoencoder, deep
      belief networks, etc.). Optimal node connection weights are obtained with algorithm
      optimization and fine-tuning of hyperparameters. The loss function is evaluated on the basis
      of "mse", as it is one of the best performance criteria for regression. (Bu cümlenin
      Furthermore, for the minimization of the loss function, an optimization algorithm for
      "backpropagation" weight update (e.g. quasi-Newton limited-memory
      Broyden-Fletcher-Goldfarb-Shanno (L-BFGS), stochastic gradient descent (SGD), adaptive moment
      estimation (Adam), etc.) is utilized.
    
  