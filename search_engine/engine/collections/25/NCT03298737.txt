
    
      This laboratory studies visual perception with a focus on the interaction between eye
      movements and attention. It is well established that attending to a stimulus can profoundly
      alter perception. For example, attending to a speaker at a crowded party can almost
      completely filter background both in terms of auditory noise and visual distractions.
      Although laboratory studies have traditionally investigated the effects of attentional
      changes in the absence of eye movements, under natural conditions, visual attention is often
      accompanied by orienting movements to direct our head and eyes towards the relevant objects
      of interest. Recent work has suggested that these orienting movements affect perception in a
      manner similar to covert attention. The proposed studies will investigate how eye movements
      contribute to perception and attention.

      The research covered by this protocol combines traditional "button-press" psychophysics with
      non-invasive eye-tracking to investigate the interaction between eye movements and
      perception. Subjects will perform simple perceptual tasks, such as judging the orientation or
      direction of a visual stimulus, while their eye position is monitored with a video
      eye-tracker. This approach (combining psychophysics and eye-tracking) is flexible, low risk,
      and fast when compared with neurophysiological studies. However, by focusing on low-level
      perceptual tasks, the results will be interpretable in the context of larger studies of
      neurophysiological responses in the visual system.

      The investigators hope that this basic research will ultimately have both applied and
      clinical significance. For example, understanding how perception is influenced by attention
      and eye-movements in neurotypical populations may provide non-invasive and naturalistic ways
      to identify and diagnose psychiatric disorders. Additionally, understanding how eye-movements
      interact with sensory encoding has the potential to improve machine learning algorithms for
      vision and navigation (These are not a part of the current study, but a potential future
      impact).
    
  