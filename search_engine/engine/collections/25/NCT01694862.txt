
    
      There are many well-established reasons that support the rationale for integrating or linking
      sexual and reproductive health (SRH) and HIV services in developing countries with
      generalized HIV epidemics - primarily in sub-Saharan Africa. Yet the evidence base for the
      impact of integrated service delivery on health outcomes and costs remains weak. Partly this
      is a result of methodological difficulties.

      There is an emerging body of literature addressing the challenges of using randomized
      controlled trials to assess the impact of public health interventions. Particularly in cases
      such as the Integra Initiative, where the causal chain (between intervention and outcome) is
      long, and where there are is a broad range of outcomes that need to be explored, and where
      there is already some a degree of integration occurring in some clinic settings, attempting
      to conduct a randomized controlled trial is not appropriate. Consistent with evaluation
      designs described by Habicht and colleagues, the Integra design includes evaluation of
      performance and impact to try to make two types of causal inference: adequacy and
      plausibility.

      Evaluation of adequacy will assess whether the expected changes in provision, service
      utilisation and cost-effectiveness have occurred in intervention facilities. Evaluation of
      impact will assess the plausibility that changes in service, health and behavioral outcomes
      are due to the Integra Initiative. The case for such plausibility will be built from the
      following strands of evidence:

        -  Comparing findings in 'intervention' facilities with those in facilities chosen as
           'comparison' sites prior to the evaluation

        -  Exploring a dose-response relationship between the measured extent of integration and
           the study outcomes

        -  Measuring changes in performance over time, to demonstrate a logical sequence between
           the intervention (integration) and outcomes.

        -  Measuring change in each step of the logic model - a prerequisite for any attribution to
           the intervention

        -  Triangulating findings from a mix of research methods to capture a range of perspectives
           and insights from different disciplines.

      The study will employ a controlled pre- and post-test quasi-experimental, or non-randomised,
      design and utilises multiple research methods (cohort study, community survey, clinic
      assessments, costing tools and qualitative interviews). Since the research is being conducted
      in real-life health delivery settings where programmatic contamination is possible due to
      ongoing health programme interventions over the study period, the control group will be
      referred to as a 'comparison group', for which outcomes will be compared over time up to two
      years after implementation.
    
  