
    
      The December 2019 outbreak of COVID-19 has now evolved into a public health emergency of
      global concern. Given the rapid spread of infection, the rapid depletion of hospital
      resources due to high influxes of patients, and the current absence of specific therapeutic
      drugs and vaccines for treatment of COVID-19 infection, it is essential to detect onset of
      the disease at its early stages. Radiological examinations, the most common of which are
      posteroanterior chest X-ray (PCX) images, play an important role in the diagnosis of
      COVID-19. The objective of this study is to assess three configurations of two convolutional
      deep neural network architectures for the classification of COVID-19 PCX images. The primary
      experimental dataset consisted of 115 COVID-19 positive and 115 COVID-19 negative PCX images,
      the latter comprising roughly equally many pneumonia, emphysema, fibrosis, and healthy images
      (230 total images). Two common convolutional neural network architectures were used, VGG16
      and DenseNet121, the former initially configured with off-the-shelf (OTS) parameters and the
      latter with either OTS or exclusively X-ray trained (XRT) parameters. The OTS parameters were
      derived from training on the ImageNet dataset, while the XRT parameters were obtained from
      training on the NIH chest X-ray dataset, ChestX-ray14. A final, densely connected layer was
      added to each model, the parameters of which were trained and validated on 87% of images from
      the experimental dataset, for the task of binary classification of images as COVID-19
      positive or COVID-19 negative. Each model was tested on a hold-out set consisting of the
      other 13% of images. Performance metrics were calculated as the average over five random
      80%-20% splits of the images into training and validation sets, respectively.
    
  