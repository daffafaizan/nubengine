
    
      A research navigation platform displays the intraoperative position of the endoscope inside
      the airways, and shows its position in 3D maps made from the patients' own preoperative
      images (PET-- CT, PET--MRI or fMRI). Images are acquired ahead of study inclusion. The
      navigation system acquires position data, first from a videobronchoscope, then from an
      EBUS--scope (same sort of output data acquired from both endoscopes) equipped with a position
      sensor for electromagnetic tracking.

      From intraoperative position data, the accuracy of the image--to--patient registration (for
      CT, PET--CT, PET--MRI and fMRI) and the navigation system accuracy are calculated.

      Electromagnetic navigation fused with available image modalities can be used to navigate
      directly and precisely to the area with highest suspicion of malignancy. Multimodal image
      guiding systems with functional imaging may thereby lead to improvements in endoscopic lung
      cancer staging, f. i. in diagnostic yield, procedure time and safety.
    
  