
    
      Positron emission tomography (PET)/ computerized tomography (CT), with the use of several
      tracers, among which fluoro deoxyglucose (FDG) is the most prevalent, has become a principal
      imaging modality in oncology. The PET and CT components reflect metabolic and anatomic
      information, respectively. PET images are based on detecting two annihilation 511 KeV photons
      that are produced by positron emitting isotopes. The longer the acquisition time, the more
      photons are detected and processed, resulting in better image quality. However, long scan
      times (typically 20-40 minutes per scan) are less convenient to patients, and may result in
      patient motion and misalignment. Over the years, several methods, such as 3D and time of
      flight acquisitions, have been developed to compensate for the degradation in image quality
      as a result of shortening of the scanning time. Recently, several studies have used machine
      learning to produce diagnostic images from low quality images. Xiang et al compared PET
      images of the brain that were acquired in 3 minutes (i.e., low-quality PET (LPET)) with
      standard PET images (i.e., SPET) that were acquired in 12 minutes. They have combined LPET
      and T1 weighted images using deep neural networks (DNN) to produce diagnostic PET images
      equivalent to SPET images.

      The goal of our study is to produce diagnostic PET images with 10 seconds acquisition time
      per bed position using DNN algorithms developed at the CILAB laboratory in the imaging
      department of Sheba.

      The algorithms were previously successfully validated for the denoising of ultra-low dose
      chest CT scans, making them suitable for lung cancer screening. The algorithms are based on
      the locally-consistent non-local means (LC-NLM) algorithm.

      The LC-NLM algorithm uses fast approximate nearest neighbors (ANN) to find the most similar
      high-SNR patch, in a purposely built database, for each noisy patch in the input image (Green
      et al.) ] We propose to use the recently introduced non-local neural networks (Wang et al.)
      in order to stack the LC-NLM into a fully trainable, locally-consistent nonlocal block
      (LC-NLB). The original non-local networks combines the ideas of the classical non-local means
      (NLM) algorithm (Buades et al.) into a neural network block, which computes the output at a
      specific position as a weighted sum of the features at all positions.
    
  