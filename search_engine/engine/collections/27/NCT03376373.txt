
    
      Individuals with autism spectrum disorder (ASD) are known to have difficulty in the
      recognition of facial emotion. Such deficits in facial emotion recognition (FER) are thought
      to cause or exacerbate social disability in ASD by preventing 1) accurate detection of
      social/emotional information conveyed through the face and, subsequently 2) the deployment of
      emotionally appropriate responses. Consistent with this model, FER deficits are correlated
      with social disability in ASD and confer morbidity above and beyond core symptoms.

      The long-term goal is to understand how FER networks can be manipulated for therapeutic and
      preventative purposes. In this trial, investigators are testing the feasibility of an
      intervention that capitalizes on our previously developed brain-computer interface (BCI) to
      promote FER in a mixed virtual reality world. The new "FER Assistant" tool (deployed on a
      tablet - iPad) is intended to aid users in detecting emotions and intents of 'avatars'
      inhabiting a virtual world, and will provide users with a highly realistic testbed for
      practicing FER skills in concert with BCI.
    
  